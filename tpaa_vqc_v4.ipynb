{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47880e5",
   "metadata": {},
   "source": [
    "# 2-sins dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5770695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation (Updated with Composite Sine Wave) ---\n",
    "num_samples = 500\n",
    "eps = 0.2\n",
    "lb, ub = -np.pi, np.pi\n",
    "\n",
    "# Composite function (scaled into ~[0, 1] before noise)\n",
    "f = lambda x: (np.sin(5.0 * x) + 0.5 * np.sin(8.0 * x)) / 4.0 + 0.5\n",
    "\n",
    "t = np.linspace(lb, ub, num_samples)\n",
    "data = f(t) + eps * (2 * np.random.rand(num_samples) - 1)\n",
    "\n",
    "# --- SAX Transformation ---\n",
    "sax = SymbolicAggregateApproximation(n_bins=3, strategy=\"quantile\")\n",
    "sax_sequence = sax.fit_transform(data.reshape(1, -1))[0]  # reshape redundancy removed\n",
    "\n",
    "# --- Windowed dataset (X -> next-symbol y) ---\n",
    "window_size = 10\n",
    "X_sax = np.array([sax_sequence[i:i + window_size] for i in range(len(sax_sequence) - window_size)])\n",
    "y_sax = np.array([sax_sequence[i + window_size]   for i in range(len(sax_sequence) - window_size)])\n",
    "\n",
    "# --- Better Angle Mapping (more symmetric + avoids extremes) ---\n",
    "# Map symbols to angles in (0, pi), evenly spaced to reduce bias and keep good separation.\n",
    "# a = pi/6, b = pi/2, c = 5pi/6\n",
    "map_dict = {'a': np.pi/6, 'b': np.pi/2, 'c': 5*np.pi/6}\n",
    "X_angles = np.vectorize(map_dict.get)(X_sax)\n",
    "\n",
    "# --- Labels (remove hard-coded fit redundancy) ---\n",
    "# This learns classes from y_sax directly. For n_bins=3 it will be ['a','b','c'] in practice,\n",
    "# but will also stay correct if you later switch to 4 or 5 bins.\n",
    "lb_bin = LabelBinarizer()\n",
    "y_one_hot = lb_bin.fit_transform(y_sax)\n",
    "\n",
    "# Optional: sanity print\n",
    "print(\"Classes:\", lb_bin.classes_)\n",
    "print(\"X_angles shape:\", X_angles.shape, \"y_one_hot shape:\", y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c44740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation ---\n",
    "t = np.linspace(0, 4*np.pi, 500)\n",
    "data = np.sin(t) + np.random.normal(0, 0.1, 500)\n",
    "\n",
    "sax = SymbolicAggregateApproximation(n_bins=3, strategy='uniform')\n",
    "data_reshaped = data.reshape(1, -1)\n",
    "sax_sequence = sax.fit_transform(data_reshaped)[0] \n",
    "\n",
    "X_sax = []\n",
    "y_sax = []\n",
    "window_size = 10\n",
    "\n",
    "for i in range(len(sax_sequence) - window_size):\n",
    "    X_sax.append(sax_sequence[i:i + window_size])\n",
    "    y_sax.append(sax_sequence[i + window_size])\n",
    "\n",
    "X_sax = np.array(X_sax)\n",
    "y_sax = np.array(y_sax)\n",
    "\n",
    "# 1. Wider Angle Mapping\n",
    "# map a-c to angles between 0 and pi\n",
    "map_dict = {'a': 0.2, 'b': 1.57, 'c': 2.9}\n",
    "X_angles = np.vectorize(map_dict.get)(X_sax)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_one_hot = lb.fit_transform(y_sax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full SAX symbol sequence\n",
    "print(\"SAX sequence:\")\n",
    "print(\"\".join(sax_sequence))\n",
    "\n",
    "# Optional: print first N symbols for readability\n",
    "N = 100\n",
    "print(f\"\\nFirst {N} symbols:\")\n",
    "print(\"\".join(sax_sequence[:N]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(sax_sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_rate = sum(sax_sequence[i] != sax_sequence[i-1] for i in range(1, len(sax_sequence))) / (len(sax_sequence)-1)\n",
    "print(\"Change rate:\", change_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.step(range(100), actual_labels[:100], label='Actual', alpha=0.6, linewidth=3)\n",
    "plt.step(range(100), predicted_labels[:100], label='VQC Prediction', linestyle='--', color='orange')\n",
    "plt.title(\"Zoomed-In Prediction (First 100 Samples)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25293a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Get predictions\n",
    "# Ensure we use the full X_angles and y_one_hot for a complete picture\n",
    "y_pred_probs = vqc.predict(X_angles)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_one_hot, axis=1)\n",
    "\n",
    "# 2. Print the text report\n",
    "target_names = ['a (Low)', 'b (Mid)', 'c (High)']\n",
    "print(\"Quantum VQC Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "# 3. Plot the Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix: Predicted vs Actual SAX Symbols')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a9be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_probs_clipped = np.clip(y_pred_probs, 1e-15, 1 - 1e-15)\n",
    "vqc_log_loss = log_loss(y_one_hot, y_probs_clipped)\n",
    "\n",
    "print(f\"Final VQC Log-Loss: {vqc_log_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate individual log-loss per sample\n",
    "# Small epsilon to prevent log(0)\n",
    "eps = 1e-15\n",
    "y_probs_smooth = np.clip(y_pred_probs, eps, 1 - eps)\n",
    "individual_losses = -np.sum(y_one_hot * np.log(y_probs_smooth), axis=1)\n",
    "\n",
    "# Find top 5 hardest samples\n",
    "top_5_indices = np.argsort(individual_losses)[-5:]\n",
    "\n",
    "print(\"Top 5 Hardest Samples (Indices):\", top_5_indices)\n",
    "print(\"Losses for these samples:\", individual_losses[top_5_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08129d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the original data and mark the failure points\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot the underlying sine wave for context\n",
    "plt.plot(t, data, label='Noisy Sine Wave', color='lightgray', alpha=0.7)\n",
    "\n",
    "# Highlight the 5 samples where the VQC hit the max log-loss penalty\n",
    "# Note: window_size is subtracted because X_sax starts at index 10\n",
    "failure_times = t[top_5_indices + window_size]\n",
    "failure_values = data[top_5_indices + window_size]\n",
    "\n",
    "plt.scatter(failure_times, failure_values, color='red', s=100, \n",
    "            label='Hardest Samples (Max Log-Loss)', zorder=5)\n",
    "\n",
    "plt.title(\"Locations of Maximum Prediction Error\")\n",
    "plt.xlabel(\"Time (t)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aee4e7",
   "metadata": {},
   "source": [
    "# QSPAX-VQC With Trend Analysis - Version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90744059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Data Preparation (Composite Sine Wave + SAX + Trend channel) ---\n",
    "num_samples = 500\n",
    "eps = 0.2\n",
    "lb, ub = -np.pi, np.pi\n",
    "\n",
    "f = lambda x: (np.sin(5.0 * x) + 0.5 * np.sin(8.0 * x)) / 4.0 + 0.5\n",
    "\n",
    "t = np.linspace(lb, ub, num_samples)\n",
    "data = f(t) + eps * (2 * np.random.rand(num_samples) - 1)\n",
    "\n",
    "# --- SAX on raw level ---\n",
    "sax = SymbolicAggregateApproximation(n_bins=3, strategy=\"quantile\")\n",
    "sax_sequence = sax.fit_transform(data.reshape(1, -1))[0]  # letters 'a','b','c'\n",
    "\n",
    "window_size = 8\n",
    "\n",
    "# Sliding-window SAX dataset (level symbols)\n",
    "X_sax = []\n",
    "y_sax = []\n",
    "for i in range(len(sax_sequence) - window_size):\n",
    "    X_sax.append(sax_sequence[i : i + window_size])\n",
    "    y_sax.append(sax_sequence[i + window_size])\n",
    "\n",
    "X_sax = np.array(X_sax)\n",
    "y_sax = np.array(y_sax)\n",
    "\n",
    "# --- Trend channel from raw data (first difference) aligned to same windows ---\n",
    "# d[t] = data[t] - data[t-1], with d[0]=0\n",
    "d = np.diff(data, prepend=data[0])\n",
    "\n",
    "X_trend = []\n",
    "for i in range(len(d) - window_size):\n",
    "    X_trend.append(d[i : i + window_size])\n",
    "X_trend = np.array(X_trend)\n",
    "\n",
    "# --- Map SAX symbols -> angles (level channel) ---\n",
    "map_dict = {\"a\": 0.2, \"b\": 1.57, \"c\": 2.9}\n",
    "X_level_angles = np.vectorize(map_dict.get)(X_sax).astype(float)  # (N, window_size)\n",
    "\n",
    "# --- Map trend values -> angles (trend channel), robust scaling + clipping ---\n",
    "# scale so typical magnitudes land inside [-pi, pi]\n",
    "scale = np.pi / (np.percentile(np.abs(X_trend), 95) + 1e-9)\n",
    "X_trend_angles = np.clip(X_trend * scale, -np.pi, np.pi)          # (N, window_size)\n",
    "\n",
    "# --- Final input matrix: concatenate [level | trend] ---\n",
    "# Use a custom feature map with 2*window_size input params (RY for level, RZ for trend)\n",
    "X_angles = np.hstack([X_level_angles, X_trend_angles])            # (N, 2*window_size)\n",
    "\n",
    "# --- One-hot targets (force 3 columns always) ---\n",
    "lb_bin = LabelBinarizer()\n",
    "lb_bin.fit([\"a\", \"b\", \"c\"])\n",
    "y_one_hot = lb_bin.transform(y_sax)                               # (N, 3)\n",
    "\n",
    "print(\"X_angles shape:\", X_angles.shape)  # (N, 12) when window_size=6\n",
    "print(\"y_one_hot shape:\", y_one_hot.shape)\n",
    "print(\"unique y_sax:\", np.unique(y_sax))\n",
    "\n",
    "\n",
    "# --- 3. Callback & Setup ---\n",
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "def callback_graph(*args):\n",
    "    clear_output(wait=True)\n",
    "    obj_func_eval = args[1] if len(args) == 2 else args[2]\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 4. Model Construction (UPDATED for level+trend inputs) ---\n",
    "# X_angles shape is (N, 2*window_size). We need num_qubits = window_size, not 2*window_size.\n",
    "# The feature map will consume 2*window_size input parameters and apply them onto window_size qubits.\n",
    "num_qubits = window_size\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "def level_trend_with_cz_chain(num_qubits: int, reps: int = 1):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"LEVEL_TREND_CZ\")\n",
    "    x = ParameterVector(\"x\", length=2*num_qubits)\n",
    "\n",
    "    for _ in range(reps):\n",
    "        for i in range(num_qubits):\n",
    "            qc.ry(x[i], i)                 # level\n",
    "            qc.rz(x[num_qubits + i], i)    # trend\n",
    "        for i in range(num_qubits - 1):\n",
    "            qc.cz(i, i+1)\n",
    "\n",
    "    return qc\n",
    "\n",
    "feature_map = level_trend_with_cz_chain(window_size, reps=1)\n",
    "\n",
    "\n",
    "ansatz = RealAmplitudes(num_qubits=num_qubits, entanglement=\"linear\", reps=2)\n",
    "optimizer = COBYLA(maxiter=100)\n",
    "sampler = StatevectorSampler()\n",
    "\n",
    "# Keep interpret, but avoid class-mismatch if a symbol is missing in this run\n",
    "present = np.unique(y_sax)\n",
    "num_classes_present = len(present)  # could be 2 or 3\n",
    "\n",
    "def interpret_mod_classes(bitstring):\n",
    "    return bin(bitstring).count(\"1\") % num_classes_present\n",
    "\n",
    "# If you want to FORCE 3 classes regardless, keep interpret_3_bins AND ensure y_sax contains all 3 symbols.\n",
    "# Otherwise, use data-driven classes:\n",
    "vqc = VQC(\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    interpret=interpret_mod_classes,\n",
    "    output_shape=num_classes_present,\n",
    "    loss=\"cross_entropy\",\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "print(\"unique y_sax:\", present)\n",
    "print(\"y_one_hot shape:\", y_one_hot.shape)\n",
    "print(\"num_classes_present:\", num_classes_present)\n",
    "\n",
    "# Use only the columns for present classes (prevents loss expecting 3 when only 2 are present)\n",
    "class_to_col = {c: i for i, c in enumerate([\"a\", \"b\", \"c\"])}\n",
    "cols = [class_to_col[c] for c in present]\n",
    "y_used = y_one_hot[:, cols]\n",
    "\n",
    "# --- 5. Model Training ---\n",
    "vqc.fit(X_angles, y_used)\n",
    "vqc.warm_start = True\n",
    "\n",
    "\n",
    "# --- 6. Results ---\n",
    "score = vqc.score(X_angles, y_used)\n",
    "print(f\"Final Classification Accuracy: {score:.2f}\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "predicted = vqc.predict(X_angles)              # shape (N, num_classes_present)\n",
    "pred_labels = np.argmax(predicted, axis=1)\n",
    "true_labels = np.argmax(y_used, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.step(range(len(true_labels)), true_labels, label=\"Actual Target\", where=\"post\", alpha=0.6, linewidth=2)\n",
    "plt.step(range(len(pred_labels)), pred_labels, label=\"VQC Prediction\", where=\"post\", linestyle=\"--\", alpha=0.8)\n",
    "\n",
    "# label y-axis with the symbols actually present\n",
    "plt.yticks(range(num_classes_present), present.tolist())\n",
    "\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.title(f\"Next-Symbol Prediction (Accuracy: {score:.2f})\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit746env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
